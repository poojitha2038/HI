### **1. Install Required Libraries**
!pip install diffusers transformers accelerate torch
!pip install dalle-mini
### **2. Using Stable Diffusion**
from diffusers import StableDiffusionPipeline
import torch
# Load Stable Diffusion model
model_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = pipe.to("cuda")  # use GPU if available
# Generate image from text
prompt = "a futuristic city with flying cars at sunset"
image = pipe(prompt).images[0]
# Save image
image.save("generated_image.png")
### **3. Using DALL·E Mini (Craiyon)**
from dalle_mini import DalleBart, DalleBartProcessor
import torch
# Load pre-trained DALL·E mini
model = DalleBart.from_pretrained("dalle-mini/dalle-mini/mega-1-fp16:latest")
processor = DalleBartProcessor.from_pretrained("dalle-mini/dalle-mini/mega-1-fp16:latest")
# Prompt
prompt = "a cartoon illustration of a robot reading a book"
inputs = processor([prompt], return_tensors="pt").to("cuda")
generated_ids = model.generate(**inputs, num_beams=4, max_length=128)
generated_images = processor.decode(generated_ids)
print("Generated Images:", generated_images)
